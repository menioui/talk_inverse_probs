{
 "metadata": {
  "name": "",
  "signature": "sha256:0474439bd1aa9fc2ac1b657136864d462aae3c356fb4d2f215383bbe25f8ca8b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.html.widgets import interact, interactive, fixed\n",
      "from IPython.html import widgets\n",
      "from IPython.display import clear_output, display\n",
      "np.set_printoptions(precision=3, formatter={'float_kind':'{:3f}'.format}) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Discrete ill-posed inverse problems\n",
      "--------------------------------------\n",
      "\n",
      "Simple example system of equations:\n",
      "\n",
      "$$x + 3 y = 2$$\n",
      "\n",
      "$$4x - y = 1$$\n",
      "\n",
      "Representable as the system:\n",
      "\n",
      "\n",
      "$$\\begin{pmatrix}\n",
      "1 & 3\\\\\n",
      "4 & -1\n",
      "\\end{pmatrix}\\begin{pmatrix}\n",
      "x\\\\\n",
      "y\n",
      "\\end{pmatrix}=\\begin{pmatrix}\n",
      "2\\\\\n",
      "1\n",
      "\\end{pmatrix}$$\n",
      "\n",
      "or \n",
      "\n",
      "$$Ax = b$$\n",
      "\n",
      "- If $A$ has an inverse matrix $A^{-1}$ that is available, then $x = A^{-1} b$.\n",
      "\n",
      "- If $A$ is not invertible (i.e. a singular matrix), a generalized inverse (or pseudo-inverse) $A^{\\dagger}$ can be defined to allow for an approximated solution $x = A^{\\dagger} b$.\n",
      "\n",
      "- Problems with measurement or quantization noise can be written as $Ax = b + e$, where exact data $b$ and noise sources $e$ cannot be practically separated from each other\n",
      "\n",
      "- What we are usually after practically is something along the lines of\n",
      "\n",
      "$$\\min_x||Ax - b||_2$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A nice well-posed problem\n",
      "# easy to compute direct solution, even when there is noise\n",
      "A = array([[1, 3],\n",
      "           [4, -1]])\n",
      "\n",
      "b = [2, 1]\n",
      "\n",
      "x = linalg.solve(A, b + 0.001*random.randn(2))\n",
      "\n",
      "display(A.dot(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a singular (rank-deficient) problem: no unique solution. But minimum-norm least squares solution exists.\n",
      "@widgets.interact(n=(4,10))\n",
      "def g(n=4):\n",
      "    A = random.randn(n,n)\n",
      "    #A[1] = A[0] + A[1]\n",
      "    A[3] = A[1] - A[2]\n",
      "    b = arange(n)\n",
      "    \n",
      "    #x = linalg.solve(A, b)\n",
      "    x = linalg.lstsq(A,b)[0]\n",
      "    \n",
      "    print \"b=\", b\n",
      "    print \"A * x = \"\n",
      "    display(A.dot(x).astype(float))\n",
      "    #print\n",
      "    #print \"condition number:\", linalg.cond(A)\n",
      "    #u,s,v = linalg.svd(A, full_matrices=False)\n",
      "    #plot(s)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Highly unstable problem: image deblurring (deconvolution)\n",
      "print \"Loaded image:\"\n",
      "from scipy import misc\n",
      "original = imread(\"data/cleveland.png\").mean(axis=2)\n",
      "m,n = original.shape\n",
      "figure(figsize=(15, 10))\n",
      "imshow(original, cmap=cm.gray)\n",
      "_=colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here we define a gaussian blurring operator\n",
      "from pyret import psfGauss, psfMatrix, tsvd_fft, tik_fft\n",
      "psf, center = psfGauss([m, n], 3)\n",
      "A = psfMatrix(psf, boundary='periodic')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Apply blur to loaded image (equiv. to a simple matrix-vector product)\n",
      "# Loaded functions use the FFT instead of direct linear algebra routines\n",
      "b = A * original + 0.00001 * random.randn(m, n)\n",
      "figure(figsize=(15, 10))\n",
      "imshow(b, cmap=cm.gray)\n",
      "colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now, attempt direct solution to the blurring problem\n",
      "# Blows up\n",
      "x, spec = tsvd_fft(b, psf, center, 1e-19)\n",
      "figure(figsize=(15, 10))\n",
      "imshow(x, cmap=cm.gray)\n",
      "colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Posedness\n",
      "-----------\n",
      "\n",
      "A mathematical problem is said to be *well-posed* (in the sense of Hadamard) if: \n",
      "\n",
      "1. There exists a solution\n",
      "2. The solution is unique\n",
      "3. The solution depends continuously upon input data\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Example: 1st-Type Fredholm Integral equations\n",
      "-------------------\n",
      "As an example, consider solving the integral equation:\n",
      "$$\\int_\\Omega K\\left(x, s \\right) f\\left(s \\right) ds = g\\left(x \\right)$$\n",
      "If a solution $f$ is perturbed by:\n",
      "\n",
      "$$\\Delta f_p =\\varepsilon \\sin \\left( {2\\pi ps} \\right) $$\n",
      "\n",
      "for some non-zero constant $ \\varepsilon$, then the corresponding perturbation on the right-hand side is:\n",
      "\n",
      "$$ \\Delta g_p = \\varepsilon\\int\\limits_\\Omega {K\\left( {x,s} \\right)\\sin \\left( {2\\pi ps} \\right)ds}$$\n",
      "\n",
      "By the Riemann-Lebesgue lemma, it follows that, for any $\\varepsilon \\ne 0$, this perturbation vanishes as $p \\to \\infty$, while the ratio of perturbations $\\frac{{ {\\Delta {f_p}}}}{{{\\Delta {g_p}}}}$ will grow without bound.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For discrete ill-posed problems:\n",
      "-------------------------------\n",
      "\n",
      "For the problem $Ax = b + e$, consider the SVD of A:\n",
      "\n",
      "$$A = U \\Sigma V^T$$\n",
      "\n",
      "where $U$ and $V$ are unitary matrices, and $\\Sigma$ is a matrix with non-zero singular values along the diagonal. The number of non-zero singular values is called the rank of A, and is equal to the number of linearly independant columns or rows.\n",
      "\n",
      "The ratio of the largest (first) singular value to the smallest is called the condition number of $A$.\n",
      "\n",
      "A rank $k$ approximation $A_k$ of $A$ can be obtained from the SVD as\n",
      "$${A_k} = \\sum\\limits_{i = 1}^k {{\\sigma _j}{u_j}v_j^T}, $$\n",
      "with $\\sigma_{1} \\ge \\sigma_{2} \\ge \\ldots \\ge \\sigma_{k} \\ge 0$. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print original.shape\n",
      "u, s, v = linalg.svd(original)\n",
      "figure(figsize=(15, 5))\n",
      "ylim(0,20)\n",
      "plot(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below are some plots of ${{\\sigma _j}{u_j}v_j^T}$ for $i = 1$ to $20$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15,10))\n",
      "print \"First few singular components:\"\n",
      "for i in xrange(20):\n",
      "    pic = s[i]*outer(u.T[i], v[i])\n",
      "    subplot(4,5,i+1)\n",
      "    imshow(pic, cmap=cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@widgets.interact(r=(1, 200))\n",
      "def show_rank(r=1):\n",
      "    Ar = zeros((len(u), len(v)))\n",
      "\n",
      "    for i in xrange(r):\n",
      "        Ar += s[i] * outer(u.T[i], v[i])\n",
      "\n",
      "    figure(figsize=(15, 5))\n",
      "    subplot(121)\n",
      "    title(\"original\")\n",
      "    imshow(original, cmap=cm.gray)\n",
      "    subplot(122)\n",
      "    title(\"rank-\"+str(r)+\" appx\")\n",
      "    imshow(Ar, cmap=cm.gray)\n",
      "    print\n",
      "    print \"compression :\", 100* r*sum(original.shape) / float(prod(original.shape)), \"%\"\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Truncated SVD regularization:\n",
      "--------------------------------\n",
      "\n",
      "If $A$ is invertible, then \n",
      "\n",
      "$$A^{-1} = V \\Sigma^{-1} U^T = {\\sum {\\frac{{{v_i}u_i^T}}{{{\\sigma _i}}}} }$$\n",
      "where $\\Sigma^{-1}$ is just $\\Sigma$ with each non-zero singular value inverted.\n",
      "\n",
      "Otherwise, we can compute a rank-k pseudoinverse $A^{\\dagger}_k$:\n",
      "\n",
      "$$A^{\\dagger}_k=  {\\sum\\limits_{i = 1}^k {\\frac{{{v_i}u_i^T}}{{{\\sigma _i}}}} }$$\n",
      "\n",
      "Direct application of this pseudoinverse to the data $b+e$ gives the TSVD solution\n",
      "\n",
      "$$\\hat x_k=A^{\\dagger}_k \\left(b+e \\right) = \\sum\\limits_{i = 1}^k {\\frac{{u_i^Tb}}{{{\\sigma _i}}}{v_i}}  + \\frac{{u_i^Te}}{{{\\sigma _i}}}{v_i}.$$\n",
      "\n",
      " If $A$ is an ill-conditioned matrix, the terms $\\frac{{u_i^Te}}{{{\\sigma _i}}}{v_i}$ related to the  noise may dominate for small singular values \n",
      " \n",
      " Solution: truncate the sum early enough that the error terms are not amplified! \n",
      " \n",
      " This process of replacing the original problem with one more suitable for numerical treatment is called regularization, and the truncation index $k$ is called a regularization parameter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 3))\n",
      "plot(abs(array(spec)))\n",
      "#xlim(0,100000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TSVD regularization\n",
      "@widgets.interact(k=(0, 100000))\n",
      "def showsol(k=270000):\n",
      "    global spec\n",
      "    tol = spec[k]\n",
      "    x, _ = tsvd_fft(b, psf, center, tol)\n",
      "    figure(figsize=(15, 15))\n",
      "    subplot(121)\n",
      "    title(\"blurred\")\n",
      "    imshow(b, cmap=cm.gray)\n",
      "    subplot(122)\n",
      "    title(\"k=%s\"%str(k))\n",
      "    imshow(x, cmap=cm.gray)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tikhonov regularization:\n",
      "-------------------------\n",
      "\n",
      "Instead of solving \n",
      "$$\\min_x||Ax - b||_2$$\n",
      "\n",
      "instead solve \n",
      "\n",
      "$$ \\min_x||Ax - b||_2  + \\alpha ||\\Gamma x||_2$$\n",
      "\n",
      "This directly seeks to balance accuracy with tractability\n",
      "\n",
      "If $\\Gamma = I$ and you already have the SVD of A, then the Tikhonov solution is given by:\n",
      "\n",
      "$$\\hat x = {\\sum\\limits_{i = 1}^k \\frac{\\sigma_i^2}{\\sigma_i^2 + \\alpha^2} {\\frac{{{v_i}u_i^T}}{{{\\sigma _i}}}} }b$$\n",
      "\n",
      "otherwise, you can compute it by solving the normal equations:\n",
      "\n",
      "$$ \\left( A^T A + \\alpha \\Gamma^T \\Gamma\\right)x = A^T b$$ "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Tikhonov regularization\n",
      "@widgets.interact(a=(-7., 0))\n",
      "def showsol(a=0):\n",
      "    x = tik_fft(b, psf, alpha=10**a)\n",
      "    figure(figsize=(15, 15))\n",
      "    subplot(121)\n",
      "    title(\"blurred\")\n",
      "    imshow(b, cmap=cm.gray)\n",
      "    subplot(122)\n",
      "    title(\"$\\\\alpha$=%s\"%str(10**a))\n",
      "    imshow(x, cmap=cm.gray)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Useful articles:\n",
      "------------------------\n",
      "- http://en.wikipedia.org/wiki/Condition_number\n",
      "- http://en.wikipedia.org/wiki/Least_squares\n",
      "- http://en.wikipedia.org/wiki/Singular_value_decomposition\n",
      "- http://en.wikipedia.org/wiki/Tikhonov_regularization\n",
      "- http://en.wikipedia.org/wiki/Matrix_decomposition\n",
      "\n",
      "Related texts:\n",
      "--------\n",
      "- [\"Numerical Linear Algebra\"](http://www.amazon.com/Numerical-Linear-Algebra-Lloyd-Trefethen/dp/0898713617) by Nick Trefethen\n",
      "- [\"Rank-Deficient And Discrete Ill-Posed Inverse Problems\"](http://www.amazon.com/Rank-Deficient-Discrete-Ill-Posed-Problems-Mathematical/dp/0898714036) by Per Christian Hansen"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Possible topics for future meetup talks:\n",
      "-------------------------\n",
      "- Numerical solvers for linear equations & eigenvalues\n",
      "- Regularization methods (SVD, Tikhonov, LSQR, GMRES, etc)\n",
      "- Numerical optimization (problem formulation, LP, SQP, etc)\n",
      "- Heuristic computing (Simulated annealing, genetic algorithms, etc)\n",
      "- Calculus of variations w/applications\n",
      "- Signal processing (FFT, DCT, Wavelets, etc)\n",
      "- Image processing (denoising, deblurring, compression, etc)\n",
      "- Machine learning (SVM, neural nets, k-means, etc)\n",
      "- Computer vision (object detection, feature extraction, OCR, etc)\n",
      "- Graph theory (centrality measures, Dijkstra's method, A*, etc)\n",
      "- Control theory (PID, Kalman filtering, etc)\n",
      "- Dynamical systems (predator-prey, chaos theory, etc)\n",
      "- Bayesian estimation\n",
      "- Prime number theory\n",
      "- Cellular automata\n",
      "- Blind source separation (PCA, ICA, etc.)\n",
      "- Concurrent computing (parallel processing, distributed computing, CUDA, FPGAs, etc)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}